{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gong to use different models for prediction, and ensemble them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split, GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('processed data\\processed_train_Agebin.csv')\n",
    "test_df = pd.read_csv('processed data\\processed_test_Agebin.csv')\n",
    "TARGET = 'Transported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(TARGET, axis=1)\n",
    "y = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6954, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2333    False\n",
       "2589    False\n",
       "8302     True\n",
       "8177     True\n",
       "500      True\n",
       "        ...  \n",
       "5734     True\n",
       "5191    False\n",
       "5390    False\n",
       "860     False\n",
       "7270    False\n",
       "Name: Transported, Length: 6954, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = CatBoostClassifier()\n",
    "# model = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# #print(\"Performance on train data:\", model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_v = model.predict(X_valid)\n",
    "\n",
    "# y_pred_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.797962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.790768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.786454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy\n",
       "2  LGBMClassifier  0.797962\n",
       "1   XGBClassifier  0.790768\n",
       "0             SVC  0.786454"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA = [\n",
    "    SVC(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier(),\n",
    "    #CatBoostClassifier()\n",
    "]\n",
    "\n",
    "row_index = 0\n",
    "\n",
    "# Setting up the table to compare the performances of each model\n",
    "MLA_cols = ['Model', 'Accuracy']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_cols)\n",
    "\n",
    "# Iterate and store scores in the table\n",
    "for model in MLA:\n",
    "    MLA_compare.loc[row_index, 'Model'] = model.__class__.__name__\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    MLA_compare.loc[row_index, 'Accuracy'] = cv_results.mean()\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "# Present table\n",
    "MLA_compare.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "MLA_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmmm, this is the baseline, we can then do the hyperparameter tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_p = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7946638776964658\n",
      "{'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(probability = True)\n",
    "\n",
    "svc_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto']}\n",
    "\n",
    "svc_optimal = RandomizedSearchCV(svc, svc_grid, n_iter=24, scoring='accuracy', n_jobs=-1, cv=skf.split(X_p,y), verbose=2, random_state=42)\n",
    "svc_optimal.fit(X_p, y)\n",
    "print(svc_optimal.best_score_)\n",
    "print(svc_optimal.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(probability = True)\n",
    "\n",
    "# svc_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],\n",
    "#             'kernel': ['linear', 'rbf'],\n",
    "#             'gamma': ['scale', 'auto']}\n",
    "\n",
    "# svc_optimal = RandomizedSearchCV(svc, svc_grid, n_iter=12, scoring='accuracy', n_jobs=-1, cv=skf.split(X,y), verbose=2, random_state=42)\n",
    "# svc_optimal.fit(X, y)\n",
    "# print(svc_optimal.best_score_)\n",
    "# print(svc_optimal.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_grid = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [5, 7, 9]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   33.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934018320774555\n",
      "{'subsample': 0.8, 'n_estimators': 500, 'max_depth': 9, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm_optimal = RandomizedSearchCV(lgbm, param_distributions=boost_grid, n_iter=100, scoring='roc_auc', n_jobs=-1, cv=skf.split(X,y), verbose=2, random_state=42 )\n",
    "lgbm_optimal.fit(X, y)\n",
    "print(lgbm_optimal.best_score_)\n",
    "print(lgbm_optimal.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8935190841275636\n",
      "{'subsample': 0.6, 'n_estimators': 1000, 'max_depth': 5, 'learning_rate': 0.01, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb_optimal = RandomizedSearchCV(xgb, param_distributions=boost_grid, n_iter=100, scoring='roc_auc', n_jobs=-1, cv=skf.split(X,y), verbose=2, random_state=42 )\n",
    "xgb_optimal.fit(X, y)\n",
    "print(xgb_optimal.best_score_)\n",
    "print(xgb_optimal.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_op = xgb_optimal.best_estimator_\n",
    "svc_op = svc_optimal.best_estimator_\n",
    "lgbm_op = lgbm_optimal.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create Hard Voting Classifier\n",
    "Ensemble_HV = VotingClassifier(estimators= [('SVC', svc_op),\n",
    "                                           ('XBG', xgb_op),\n",
    "                                           ('LGBM', lgbm_op)],\n",
    "                              voting = 'hard')\n",
    "\n",
    "# Create Soft Voting Classifier\n",
    "Ensemble_SV = VotingClassifier(estimators= [('SVC', svc_op),\n",
    "                                           ('XBG', xgb_op),\n",
    "                                           ('LGBM', lgbm_op)],\n",
    "                              voting = 'soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Classifier: 0.7844284408787506\n",
      "Soft Voting Classifier: 0.794206357766821\n"
     ]
    }
   ],
   "source": [
    "# Return Accuracy Scores\n",
    "cv_HV = cross_val_score(Ensemble_HV, X, y, scoring='accuracy')\n",
    "cv_SV = cross_val_score(Ensemble_SV, X, y, scoring='accuracy')\n",
    "\n",
    "print('Hard Voting Classifier:' , cv_HV.mean())\n",
    "print('Soft Voting Classifier:' , cv_SV.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SVC', SVC(C=1, probability=True)),\n",
       "                             ('XBG',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0.6,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.01, max_bin=256,\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=5,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=1000, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             ('LGBM',\n",
       "                              LGBMClassifier(colsample_bytree=0.6,\n",
       "                                             learning_rate=0.01, max_depth=9,\n",
       "                                             n_estimators=500,\n",
       "                                             subsample=0.8))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_HV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SVC', SVC(C=1, probability=True)),\n",
       "                             ('XBG',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            callbacks=None, colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0.6,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=0,\n",
       "                                            gpu_id=-1, grow_policy='depthwise',\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints='',...\n",
       "                                            max_cat_to_onehot=4,\n",
       "                                            max_delta_step=0, max_depth=5,\n",
       "                                            max_leaves=0, min_child_weight=1,\n",
       "                                            missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=1000, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            predictor='auto', random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1, ...)),\n",
       "                             ('LGBM',\n",
       "                              LGBMClassifier(colsample_bytree=0.6,\n",
       "                                             learning_rate=0.01, max_depth=9,\n",
       "                                             n_estimators=500,\n",
       "                                             subsample=0.8))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ensemble_SV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on validation data HV: 0.7958596894767108\n"
     ]
    }
   ],
   "source": [
    "y_pred_hv = Ensemble_HV.predict(X_valid)\n",
    "\n",
    "print(\"Performance on validation data HV:\", f1_score(y_valid, y_pred_hv, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on validation data SV: 0.78953421506613\n"
     ]
    }
   ],
   "source": [
    "y_pred_sv = Ensemble_SV.predict(X_valid)\n",
    "\n",
    "print(\"Performance on validation data SV:\", f1_score(y_valid, y_pred_sv, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_copy = test_df.copy()\n",
    "def predict(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    Y_pred = model.predict(test_df)\n",
    "    submission_df = pd.read_csv('sample_submission.csv')\n",
    "    submission_df[\"Transported\"] = Y_pred\n",
    "    submission_df[\"Transported\"] = submission_df[\"Transported\"].astype(bool)\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(lgbm_op).to_csv('submission_lgbm_optimal2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(Ensemble_HV).to_csv('submission_Ensemble_HV2.csv', index=False)\n",
    "predict(Ensemble_SV).to_csv('submission_Ensemble_SV2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e8e9fb63faf9466e114e2302c4266dde7a3ba5ab9878045504cf5e32dd70d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
